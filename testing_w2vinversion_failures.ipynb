{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test1 = pickle.load(open('./pickled_objects/test1.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "docs = pickle.load(open('./pickled_objects/docs.p','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions = pickle.load(open('./pickled_objects/predictions.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probssentences = pickle.load(open('./pickled_objects/probssentences.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probs = pickle.load(open('./pickled_objects/probs.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probsmaxdiff = pickle.load(open('./pickled_objects/probsmaxdiff.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predsmaxdiff = pickle.load(open('./pickled_objects/predsmaxdiff.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "probssentencesmaxdiff = pickle.load(open('./pickled_objects/probssentencesmaxdiff.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              id  sentiment                                             review\n",
      "21130   \"5706_2\"          0  \"This movie is like the thousand \\\"cat and mou...\n",
      "3404   \"11132_3\"          0  \"A documentarist, like any filmmaker, must con...\n",
      "14560  \"10770_7\"          1  \"With a well thought out cast, this movie was ...\n",
      "6671   \"1058_10\"          1  \"this is the best sci-fi that I have seen in m...\n",
      "10982  \"12239_1\"          0  \"Ever since I was eight years old I have been ...\n",
      "5526     \"966_7\"          1  \"2005 Toronto Film Festival Report It is offic...\n",
      "19301  \"11645_2\"          0  \"This is a review of 'Freddy Mercury The Untol...\n",
      "17060   \"5920_9\"          1  \"American icon Henry Fonda portrays \\\"Elegant\\...\n",
      "24744   \"9501_2\"          0  \"This is the page for \\\"House of Exorcism\\\", b...\n",
      "5253    \"7877_4\"          0  \"The makers of this film have created a future...\n",
      "21967   \"5442_8\"          1  \"This is a great movie. In the same genre of t...\n",
      "18609   \"7027_4\"          0  \"On the face of it, Ruiz has set out to make a...\n"
     ]
    }
   ],
   "source": [
    "print test1[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  1.  1.  0.  1.  0.  1.  0.  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print predictions[0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0           1\n",
      "doc                       \n",
      "0     0.484133    0.515867\n",
      "1     0.573073    0.426927\n",
      "2     0.261172    0.738828\n",
      "3    0.0482365    0.951763\n",
      "4     0.536646    0.463354\n",
      "5     0.335723    0.664277\n",
      "6     0.527615    0.472385\n",
      "7    0.0064288    0.993571\n",
      "8     0.594172    0.405828\n",
      "9     0.992335  0.00766541\n",
      "10     0.29742     0.70258\n",
      "11    0.464517    0.535483\n"
     ]
    }
   ],
   "source": [
    "print probs[0:12]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reviewing some mislabelled reviews (averaging):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n",
      "12500\n",
      "0.86696\n",
      "(array([    0,    11,    20, ..., 12465, 12474, 12498]),)\n",
      "0\n",
      "11\n",
      "20\n",
      "22\n",
      "23\n",
      "31\n",
      "59\n",
      "60\n",
      "61\n",
      "86\n"
     ]
    }
   ],
   "source": [
    "#indexes that were mislabeled:\n",
    "bad_inxs = np.where(predictions != test1[\"sentiment\"])\n",
    "print len(bad_inxs[0])\n",
    "print len(test1[\"sentiment\"])\n",
    "print np.size(np.where(predictions == test1[\"sentiment\"]))*1./np.size(predictions)\n",
    "print bad_inxs\n",
    "\n",
    "i = 0\n",
    "for inxs in bad_inxs[0]:\n",
    "    if i < 10:\n",
    "        print inxs\n",
    "        #print test1[\"review\"][inxs]\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One very negative sentence at end should have described whole review. 2nd sentence (inx 1) grossly mislabeled.\n",
      "Would have properly been labeled by MaxProb.\n",
      "Probs are very close.\n",
      "Prediction: 1\n",
      "Real Score: 0\n",
      "Probs:\n",
      "0    0.484133\n",
      "1    0.515867\n",
      "Name: 0, dtype: object\n",
      "\n",
      "\"This movie is like the thousand \\\"cat and mouse\\\" movies that preceded it. (The following may look like a spoiler, but it really just describes a large class of movies) There is the passionate, wise main character, his goofy but well-meaning sidekick with his ill-placed attempts at humorous comments, the initially-hostile but soon softened gorgeous lady who triggers the inevitable \\\"unlikely\\\" love story, the loved ones taken hostage, and of course the careless evil adversary with his brutal minions. Everybody has seen tons of these movies already, and \\\"National Treasure\\\" is like any one of them, with only a slightly modified wrapping. Every turn of the story was easily predicted (and I can assure you I am not the sharpest tool in the shed). I am quite tired of feeling tricked for money after exiting the theater from a Hollywood movie, and if you have ever felt that way too, heed my warning; stay miles away from this movie.\"\n",
      "\n",
      "Sentence Scores:\n",
      "            0            1 doc\n",
      "0      0.5986       0.4014   0\n",
      "1  0.00792023      0.99208   0\n",
      "2    0.369248     0.630752   0\n",
      "3    0.445318     0.554682   0\n",
      "4    0.999581  0.000419095   0\n"
     ]
    }
   ],
   "source": [
    "print \"One very negative sentence at end should have described whole review. 2nd sentence (inx 1) grossly mislabeled.\"\n",
    "print \"Would have properly been labeled by MaxProb.\"\n",
    "print \"Probs are very close.\"\n",
    "print \"Prediction:\", int(predictions[0])\n",
    "print \"Real Score:\", test1[\"sentiment\"].iloc[0]\n",
    "print \"Probs:\"\n",
    "print probs.iloc[0]\n",
    "print \"\"\n",
    "print test1[\"review\"].iloc[0]\n",
    "print \"\"\n",
    "print \"Sentence Scores:\"\n",
    "print  probssentences.loc[probssentences[\"doc\"] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Too many overly complex sentences. Also last sentence not classified negative (score of 4/10).\n",
      "MaxProb would have also failed.\n",
      "Probs are quite close.\n",
      "Prediction: 1\n",
      "Real Score: 0\n",
      "Probs:\n",
      "0    0.464517\n",
      "1    0.535483\n",
      "Name: 11, dtype: object\n",
      "\n",
      "\"On the face of it, Ruiz has set out to make a psychological thriller. Although it's not as satisfying as a classic piece in that genre, there are compensations. The tensions generated between Huppert and Balibar as women calmly but calculatingly at war over a boy they both claim are compelling; however, in a true European art-house style, Ruiz doesn't give us release of this tension as the women alternately also try to behave compassionately towards each other. The only raised voice is that of Huppert's waking from a nightmare (an uncontested irrational event in the film).<br /><br />In fact, if we follow the title, the film is as little about its thriller skeleton as Jane Campion's In The Cut. Instead it is an intergender psychological study focusing on men. The boy, Camille (Nils Hugon), decides on a practical joke, playing his mother off against an emotionally vulnerable other woman. Both women seem to pander to him rather than scold and this compounds the problem. In the background is an intemperate psychologist (Charles Berling), swift to confront the women in his life - his sister Huppert, the nanny or his pa - and so acting as a symbolic adult counterbalance to the, calm and (we learn) manipulative Camille. It is particularly interesting that, like the father in Henry James' The Turn of The Screw, Denis Podalydes' law-enforcer Father is absent for the duration of the film. Ruiz fashions an Oedipal moment out of Huppert's reaction to his return at the film's close.<br /><br />Read either as a thriller or as a psychiatric essay, this film is ultimately rather disappointing. I'm officially rather fed up with Mme Huppert's screen method, which is too buried and so I'll be looking to see her on stage before I come back to her (European - enjoyed Heaven's Gate) films again. The support is good. Ruiz does the cast no favours though. Quite apart from some poor lighting and some wilfully odd shots, its as if his direction has left characterisation quite out of reach - I'm thinking particularly of Edith Scob's Shamanic neighbour to Isabelle, who acts knowing but communicates bafflement. The set pieces do not link up to a forward driving plot - the tension I have already referred to is not only weakly dissipated but wasted in its directional potential.<br /><br />Want to see a good contemporary French thriller? Go and see L'Appartement instead. 4/10\"\n",
      "\n",
      "Sentence Scores:\n",
      "               0          1 doc\n",
      "93      0.717875   0.282125  11\n",
      "94     0.0173377   0.982662  11\n",
      "95   0.000282313   0.999718  11\n",
      "96      0.330255   0.669745  11\n",
      "97     0.0937843   0.906216  11\n",
      "98      0.634246   0.365754  11\n",
      "99      0.297044   0.702956  11\n",
      "100   0.00639879   0.993601  11\n",
      "101      0.29517    0.70483  11\n",
      "102     0.980774  0.0192262  11\n",
      "103     0.893237   0.106763  11\n",
      "104     0.178596   0.821404  11\n",
      "105     0.799543   0.200457  11\n",
      "106      0.98153  0.0184695  11\n",
      "107     0.187951   0.812049  11\n",
      "108     0.982765  0.0172349  11\n",
      "109          0.5        0.5  11\n"
     ]
    }
   ],
   "source": [
    "print \"Too many overly complex sentences. Also last sentence not classified negative (score of 4/10).\"\n",
    "print \"MaxProb would have also failed.\"\n",
    "print \"Probs are quite close.\"\n",
    "print \"Prediction:\", int(predictions[11])\n",
    "print \"Real Score:\", test1[\"sentiment\"].iloc[11]\n",
    "print \"Probs:\"\n",
    "print probs.iloc[11]\n",
    "print \"\"\n",
    "print test1[\"review\"].iloc[11]\n",
    "print \"\"\n",
    "print \"Sentence Scores:\"\n",
    "print  probssentences.loc[probssentences[\"doc\"] == 11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One very strong negative sentence- this would have been correctly classified by maxProb.\n",
      "Also a very mixed review- explains mediocre scores for both models.\n",
      "Probs are very close.\n",
      "Prediction: 1\n",
      "Real Score: 0\n",
      "Probs:\n",
      "0    0.474654\n",
      "1    0.525346\n",
      "Name: 20, dtype: object\n",
      "\n",
      "\"The story is very trustworthy and powerful. The technical side of the movie is quite fine.. even the directing of it. The main problem is with the castings, that turned that movie into almost another local and regular cliché with a great lack of impact and even greater lack of impression. Beside the small role of the father, Rafael (played impressively by Asi Dayan), all other actors were unfortunately not in their best. The role of the elder Blind girl, played by Taly Sharon, was fresh but without any intensity as the leading role. therefore the figure she acted had become mild and low profile. There were moments and episodes that looked more like a rehearsal then a real movie. But after all it's a good point to begin from and to make big improvements in the future.\"\n",
      "\n",
      "Sentence Scores:\n",
      "             0            1 doc\n",
      "244  0.0200399      0.97996  20\n",
      "245   0.258914     0.741086  20\n",
      "246   0.999992  7.58449e-06  20\n",
      "247   0.406923     0.593077  20\n",
      "248   0.140624     0.859376  20\n",
      "249   0.816588     0.183412  20\n",
      "250   0.698662     0.301338  20\n",
      "251   0.455488     0.544512  20\n"
     ]
    }
   ],
   "source": [
    "print \"One very strong negative sentence- this would have been correctly classified by maxProb.\"\n",
    "print \"Also a very mixed review- explains mediocre scores for both models.\"\n",
    "print \"Probs are very close.\"\n",
    "print \"Prediction:\", int(predictions[20])\n",
    "print \"Real Score:\", test1[\"sentiment\"].iloc[20]\n",
    "print \"Probs:\"\n",
    "print probs.iloc[20]\n",
    "print \"\"\n",
    "print test1[\"review\"].iloc[20]\n",
    "print \"\"\n",
    "print \"Sentence Scores:\"\n",
    "print  probssentences.loc[probssentences[\"doc\"] == 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only last sentence valuable. Rest make no sense and are actually somewhat negative.\n",
      "MaxProb would not have properly classified. Scores aren't so close because of first few sentences, not important.\n",
      "Prediction: 0\n",
      "Real Score: 1\n",
      "Probs:\n",
      "0    0.674869\n",
      "1    0.325131\n",
      "Name: 22, dtype: object\n",
      "\n",
      "\"Shot into car from through the windscreen, someone is playing someone else their latest song, someone else didn't react, according to the voice-over. I just wonder how that came to be made. There were too many scenes in this movie that I wondered about how come a camera was there. If the scenes shot where the Warhols descended on a BJM post-party are true then that was inexcusable exploitation to the max, if not, then it was a total fabrication, either way it made me uncomfortable, if that was the purpose? All the way thru this movie I kept wondering how the footage came about. Taken at face value, a nice portrait of the (tortured) genius we all believe ourselves to be.\"\n",
      "\n",
      "Sentence Scores:\n",
      "            0           1 doc\n",
      "269  0.997813  0.00218711  22\n",
      "270  0.708834    0.291166  22\n",
      "271  0.413562    0.586438  22\n",
      "272  0.987708   0.0122923  22\n",
      "273  0.924647   0.0753527  22\n",
      "274   0.01665     0.98335  22\n"
     ]
    }
   ],
   "source": [
    "print \"Only last sentence valuable. Rest make no sense and are actually somewhat negative.\"\n",
    "print \"MaxProb would not have properly classified. Scores aren't so close because of first few sentences, not important.\"\n",
    "print \"Prediction:\", int(predictions[22])\n",
    "print \"Real Score:\", test1[\"sentiment\"].iloc[22]\n",
    "print \"Probs:\"\n",
    "print probs.iloc[22]\n",
    "print \"\"\n",
    "print test1[\"review\"].iloc[22]\n",
    "print \"\"\n",
    "print \"Sentence Scores:\"\n",
    "print  probssentences.loc[probssentences[\"doc\"] == 22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Only got parsed into 3 sentences instead of 6. First 4 sentences meaningless, only last 2 sentences worthwhile.\n",
      "Important because prob is VERY high for the wrong score.\n",
      "Prediction: 0\n",
      "Real Score: 1\n",
      "Probs:\n",
      "0     0.939341\n",
      "1    0.0606587\n",
      "Name: 23, dtype: object\n",
      "\n",
      "\"I'm on the opposite end of the previous comment.<br /><br />First of all, I don't think this was intended to be a straight sequel to \\\"The Jerk\\\". I mean, it's not titled \\\"The Jerk 2\\\"... it's \\\"The Jerk, Too\\\", which leads me to believe that while a lot of the character names are the same, it actually revolves around a completely different person.<br /><br />Think about it: Virtually no connection to the previous movie, other than character names; a totally different story; different cast; and the fact that it's a partial musical.<br /><br />I say give this movie some credit. It does have plenty of laughs in it.. Mark Blankfield at his prime.\"\n",
      "\n",
      "Sentence Scores:\n",
      "            0           1 doc\n",
      "275  0.975727   0.0242727  23\n",
      "276  0.993554  0.00644572  23\n",
      "277  0.848742    0.151258  23\n"
     ]
    }
   ],
   "source": [
    "print \"Only got parsed into 3 sentences instead of 6. First 4 sentences meaningless, only last 2 sentences worthwhile.\"\n",
    "print \"Important because prob is VERY high for the wrong score.\"\n",
    "print \"Prediction:\", int(predictions[23])\n",
    "print \"Real Score:\", test1[\"sentiment\"].iloc[23]\n",
    "print \"Probs:\"\n",
    "print probs.iloc[23]\n",
    "print \"\"\n",
    "print test1[\"review\"].iloc[23]\n",
    "print \"\"\n",
    "print \"Sentence Scores:\"\n",
    "print  probssentences.loc[probssentences[\"doc\"] == 23]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Think real label is wrong here and w2v is quite right.\n",
      "Prediction: 1\n",
      "Real Score: 0\n",
      "Probs:\n",
      "0    0.420767\n",
      "1    0.579233\n",
      "Name: 31, dtype: object\n",
      "\n",
      "\"Interesting film about an actual event that took place during the Civil War in Vermont. It kept my attention to the end and I don't regret viewing it. I haven't ever read any on this raid incident so I was curious to see if the rebels pulled it off. I enjoy historical films from that era.<br /><br />My major complaint is with the Confederate uniforms. They look too good!!! The acting was a little stiff at times. I like the old man eating the mashed potatoes because he didn't have any teeth. The wounded soldier playing fetch with a hound was a little strange. Overall, it was a descent film.\"\n",
      "\n",
      "Sentence Scores:\n",
      "              0         1 doc\n",
      "326  0.00501662  0.994983  31\n",
      "327    0.109255  0.890745  31\n",
      "328    0.549848  0.450152  31\n",
      "329   0.0241339  0.975866  31\n",
      "330    0.807488  0.192512  31\n",
      "331    0.720029  0.279971  31\n",
      "332    0.361526  0.638474  31\n",
      "333    0.681361  0.318639  31\n",
      "334    0.528248  0.471752  31\n"
     ]
    }
   ],
   "source": [
    "print \"Think real label is wrong here and w2v is quite right.\"\n",
    "print \"Prediction:\", int(predictions[31])\n",
    "print \"Real Score:\", test1[\"sentiment\"].iloc[31]\n",
    "print \"Probs:\"\n",
    "print probs.iloc[31]\n",
    "print \"\"\n",
    "print test1[\"review\"].iloc[31]\n",
    "print \"\"\n",
    "print \"Sentence Scores:\"\n",
    "print  probssentences.loc[probssentences[\"doc\"] == 31]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pretty much all sentences are negative until the last.\n",
      "Not correctly split into sentences.\n",
      "Incredibly close probabilities.\n",
      "Prediction: 0\n",
      "Real Score: 1\n",
      "Probs:\n",
      "0    0.500203\n",
      "1    0.499797\n",
      "Name: 59, dtype: object\n",
      "\n",
      "\"A very silly movie, this starts with a soft porn sequence, ventures into farcelike comedy in the art gallery, adds a shocker of a discovery in the hotel room then introduces a random murder for no obvious reason.<br /><br />What follows is bizarre and surreal (the stopwatch scene in particular is exquisitely unnecessary), culminating in a revelatory \\\"twist\\\" ending which is as obvious as it is unfair on the viewer (see the trivia section for precisely why it's deliberately unfair).<br /><br />The movie goes out of its way to be offensive to as many groups as possible - transsexuals, the insane, and the wonderful \\\"Huggie Bear\\\"-style racial stereotyping on the subway - and condescendingly treats the viewer like an idiot in the closing scenes, as characters endlessly explain to one another in great detail and over and over again what just happened in the film. Though the background female characters in the restaurant scene at the end are a joy to watch.<br /><br />In fact, the whole movie is a joy to watch: Despite its many, many flaws, the whole package just, well, works.\"\n",
      "[[u'a', u'very', u'silly', u'movie', u'this', u'starts', u'with', u'a', u'soft', u'porn', u'sequence', u'ventures', u'into', u'farcelike', u'comedy', u'in', u'the', u'art', u'gallery', u'adds', u'a', u'shocker', u'of', u'a', u'discovery', u'in', u'the', u'hotel', u'room', u'then', u'introduces', u'a', u'random', u'murder', u'for', u'no', u'obvious', u'reason', u'what', u'follows', u'is', u'bizarre', u'and', u'surreal', u'the', u'stopwatch', u'scene', u'in', u'particular', u'is', u'exquisitely', u'unnecessary', u'culminating', u'in', u'a', u'revelatory', u'twist', u'ending', u'which', u'is', u'as', u'obvious', u'as', u'it', u'is', u'unfair', u'on', u'the', u'viewer', u'see', u'the', u'trivia', u'section', u'for', u'precisely', u'why', u'it', u's', u'deliberately', u'unfair', u'the', u'movie', u'goes', u'out', u'of', u'its', u'way', u'to', u'be', u'offensive', u'to', u'as', u'many', u'groups', u'as', u'possible', u'transsexuals', u'the', u'insane', u'and', u'the', u'wonderful', u'huggie', u'bear', u'style', u'racial', u'stereotyping', u'on', u'the', u'subway', u'and', u'condescendingly', u'treats', u'the', u'viewer', u'like', u'an', u'idiot', u'in', u'the', u'closing', u'scenes', u'as', u'characters', u'endlessly', u'explain', u'to', u'one', u'another', u'in', u'great', u'detail', u'and', u'over', u'and', u'over', u'again', u'what', u'just', u'happened', u'in', u'the', u'film'], [u'though', u'the', u'background', u'female', u'characters', u'in', u'the', u'restaurant', u'scene', u'at', u'the', u'end', u'are', u'a', u'joy', u'to', u'watch', u'in', u'fact', u'the', u'whole', u'movie', u'is', u'a', u'joy', u'to', u'watch', u'despite', u'its', u'many', u'many', u'flaws', u'the', u'whole', u'package', u'just', u'well', u'works']]\n",
      "\n",
      "Sentence Scores:\n",
      "              0            1 doc\n",
      "693    0.999831  0.000169055  59\n",
      "694  0.00057412     0.999426  59\n"
     ]
    }
   ],
   "source": [
    "print \"Pretty much all sentences are negative until the last.\"\n",
    "print \"Not correctly split into sentences.\"\n",
    "print \"Incredibly close probabilities.\"\n",
    "print \"Prediction:\", int(predictions[59])\n",
    "print \"Real Score:\", test1[\"sentiment\"].iloc[59]\n",
    "print \"Probs:\"\n",
    "print probs.iloc[59]\n",
    "print \"\"\n",
    "print test1[\"review\"].iloc[59]\n",
    "print docs[59]\n",
    "print \"\"\n",
    "print \"Sentence Scores:\"\n",
    "print  probssentences.loc[probssentences[\"doc\"] == 59]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing parsing issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "class KaggleWord2VecUtility(object):\n",
    "    \"\"\"KaggleWord2VecUtility is a utility class for processing raw HTML text into segments for further learning\"\"\" \n",
    "    \n",
    "    # Define a function to split a review into parsed sentences\n",
    "    @staticmethod\n",
    "    def review_to_sentences( review, tokenizer, remove_stopwords=False ):\n",
    "        # Function to split a review into parsed sentences. Returns a\n",
    "        # list of sentences, where each sentence is a list of words\n",
    "        #\n",
    "        # 1. Use the NLTK tokenizer to split the paragraph into sentences\n",
    "        #print BeautifulSoup(review.decode('utf8')).get_text()\n",
    "        #print review.decode('utf8')\n",
    "        raw_sentences = tokenizer.tokenize(BeautifulSoup(review.decode('utf8')).get_text().strip())\n",
    "        #raw_sentences = tokenizer.tokenize(review.strip())\n",
    "\n",
    "        #\n",
    "        # 2. Loop over each sentence\n",
    "        sentences = []\n",
    "        for raw_sentence in raw_sentences:\n",
    "            # If a sentence is empty, skip it\n",
    "            if len(raw_sentence) > 0:\n",
    "                # Otherwise, call review_to_wordlist to get a list of words\n",
    "                sentences.append( KaggleWord2VecUtility.review_to_wordlist( raw_sentence, \\\n",
    "                  remove_stopwords ))\n",
    "        #\n",
    "        # Return the list of sentences (each sentence is a list of words,\n",
    "        # so this returns a list of lists\n",
    "        return sentences\n",
    "\n",
    "    @staticmethod\n",
    "    def review_to_wordlist( review, remove_stopwords=False ):\n",
    "        # Function to convert a document to a sequence of words,\n",
    "        # optionally removing stop words.  Returns a list of words.\n",
    "        #\n",
    "        # 1. Remove HTML\n",
    "        review_text = BeautifulSoup(review).get_text()\n",
    "        #\n",
    "        # 2. Remove non-letters\n",
    "        review_text = re.sub(\"[^a-zA-Z]\",\" \", review_text)\n",
    "        #\n",
    "        # 3. Convert words to lower case and split them\n",
    "        words = review_text.lower().split()\n",
    "        #\n",
    "        # 4. Optionally remove stop words (false by default)\n",
    "        if remove_stopwords:\n",
    "            stops = set(stopwords.words(\"english\"))\n",
    "            words = [w for w in words if not w in stops]\n",
    "        #\n",
    "        # 5. Return a list of words\n",
    "        return(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the punkt tokenizer\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'a',\n",
       "  u'very',\n",
       "  u'silly',\n",
       "  u'movie',\n",
       "  u'this',\n",
       "  u'starts',\n",
       "  u'with',\n",
       "  u'a',\n",
       "  u'soft',\n",
       "  u'porn',\n",
       "  u'sequence',\n",
       "  u'ventures',\n",
       "  u'into',\n",
       "  u'farcelike',\n",
       "  u'comedy',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'art',\n",
       "  u'gallery',\n",
       "  u'adds',\n",
       "  u'a',\n",
       "  u'shocker',\n",
       "  u'of',\n",
       "  u'a',\n",
       "  u'discovery',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'hotel',\n",
       "  u'room',\n",
       "  u'then',\n",
       "  u'introduces',\n",
       "  u'a',\n",
       "  u'random',\n",
       "  u'murder',\n",
       "  u'for',\n",
       "  u'no',\n",
       "  u'obvious',\n",
       "  u'reason',\n",
       "  u'what',\n",
       "  u'follows',\n",
       "  u'is',\n",
       "  u'bizarre',\n",
       "  u'and',\n",
       "  u'surreal',\n",
       "  u'the',\n",
       "  u'stopwatch',\n",
       "  u'scene',\n",
       "  u'in',\n",
       "  u'particular',\n",
       "  u'is',\n",
       "  u'exquisitely',\n",
       "  u'unnecessary',\n",
       "  u'culminating',\n",
       "  u'in',\n",
       "  u'a',\n",
       "  u'revelatory',\n",
       "  u'twist',\n",
       "  u'ending',\n",
       "  u'which',\n",
       "  u'is',\n",
       "  u'as',\n",
       "  u'obvious',\n",
       "  u'as',\n",
       "  u'it',\n",
       "  u'is',\n",
       "  u'unfair',\n",
       "  u'on',\n",
       "  u'the',\n",
       "  u'viewer',\n",
       "  u'see',\n",
       "  u'the',\n",
       "  u'trivia',\n",
       "  u'section',\n",
       "  u'for',\n",
       "  u'precisely',\n",
       "  u'why',\n",
       "  u'it',\n",
       "  u's',\n",
       "  u'deliberately',\n",
       "  u'unfair',\n",
       "  u'the',\n",
       "  u'movie',\n",
       "  u'goes',\n",
       "  u'out',\n",
       "  u'of',\n",
       "  u'its',\n",
       "  u'way',\n",
       "  u'to',\n",
       "  u'be',\n",
       "  u'offensive',\n",
       "  u'to',\n",
       "  u'as',\n",
       "  u'many',\n",
       "  u'groups',\n",
       "  u'as',\n",
       "  u'possible',\n",
       "  u'transsexuals',\n",
       "  u'the',\n",
       "  u'insane',\n",
       "  u'and',\n",
       "  u'the',\n",
       "  u'wonderful',\n",
       "  u'huggie',\n",
       "  u'bear',\n",
       "  u'style',\n",
       "  u'racial',\n",
       "  u'stereotyping',\n",
       "  u'on',\n",
       "  u'the',\n",
       "  u'subway',\n",
       "  u'and',\n",
       "  u'condescendingly',\n",
       "  u'treats',\n",
       "  u'the',\n",
       "  u'viewer',\n",
       "  u'like',\n",
       "  u'an',\n",
       "  u'idiot',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'closing',\n",
       "  u'scenes',\n",
       "  u'as',\n",
       "  u'characters',\n",
       "  u'endlessly',\n",
       "  u'explain',\n",
       "  u'to',\n",
       "  u'one',\n",
       "  u'another',\n",
       "  u'in',\n",
       "  u'great',\n",
       "  u'detail',\n",
       "  u'and',\n",
       "  u'over',\n",
       "  u'and',\n",
       "  u'over',\n",
       "  u'again',\n",
       "  u'what',\n",
       "  u'just',\n",
       "  u'happened',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'film'],\n",
       " [u'though',\n",
       "  u'the',\n",
       "  u'background',\n",
       "  u'female',\n",
       "  u'characters',\n",
       "  u'in',\n",
       "  u'the',\n",
       "  u'restaurant',\n",
       "  u'scene',\n",
       "  u'at',\n",
       "  u'the',\n",
       "  u'end',\n",
       "  u'are',\n",
       "  u'a',\n",
       "  u'joy',\n",
       "  u'to',\n",
       "  u'watch',\n",
       "  u'in',\n",
       "  u'fact',\n",
       "  u'the',\n",
       "  u'whole',\n",
       "  u'movie',\n",
       "  u'is',\n",
       "  u'a',\n",
       "  u'joy',\n",
       "  u'to',\n",
       "  u'watch',\n",
       "  u'despite',\n",
       "  u'its',\n",
       "  u'many',\n",
       "  u'many',\n",
       "  u'flaws',\n",
       "  u'the',\n",
       "  u'whole',\n",
       "  u'package',\n",
       "  u'just',\n",
       "  u'well',\n",
       "  u'works']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review = \"A very silly movie, this starts with a soft porn sequence, ventures into farcelike comedy in the art gallery, \\\n",
    "adds a shocker of a discovery in the hotel room then introduces a random murder for no obvious reason.<br /><br />What \\\n",
    "follows is bizarre and surreal (the stopwatch scene in particular is exquisitely unnecessary), culminating in a revelatory \\\n",
    "\\\"twist\\\" ending which is as obvious as it is unfair on the viewer (see the trivia section for precisely why it's \\\n",
    "deliberately unfair).<br /><br />The movie goes out of its way to be offensive to as many groups as possible - \\\n",
    "transsexuals, the insane, and the wonderful \\\"Huggie Bear\\\"-style racial stereotyping on the subway - and condescendingly \\\n",
    "treats the viewer like an idiot in the closing scenes, as characters endlessly explain to one another in great detail and \\\n",
    "over and over again what just happened in the film. Though the background female characters in the restaurant scene at the \\\n",
    "end are a joy to watch.<br /><br />In fact, the whole movie is a joy to watch: Despite its many, many flaws, the whole \\\n",
    "package just, well, works.\"\n",
    "\n",
    "# KaggleWord2VecUtility.review_to_sentences(test1['review'].iloc[59], tokenizer)\n",
    "KaggleWord2VecUtility.review_to_sentences(review, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Compare where MaxProb and averaging perform the same or differently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1330\n",
      "11170\n"
     ]
    }
   ],
   "source": [
    "print len(np.where(predictions != predsmaxdiff)[0])\n",
    "print len(np.where(predictions == predsmaxdiff)[0])\n",
    "#numbers add up: check\n",
    "\n",
    "inxsdiff = np.where(predictions != predsmaxdiff)[0]\n",
    "inxssame = np.where(predictions == predsmaxdiff)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500,)\n",
      "(12500,)\n"
     ]
    }
   ],
   "source": [
    "print predictions.shape\n",
    "print predsmaxdiff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1663\n",
      "1899\n"
     ]
    }
   ],
   "source": [
    "#which ones were wrong\n",
    "print len(np.where(predictions != test1['sentiment'])[0])\n",
    "print len(np.where(predsmaxdiff != test1['sentiment'])[0])\n",
    "inxsavgwrong = np.where(predictions != test1['sentiment'])[0]\n",
    "inxsmaxprobwrong = np.where(predsmaxdiff != test1['sentiment'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10054\n"
     ]
    }
   ],
   "source": [
    "#both right\n",
    "print len(np.where((predictions == test1['sentiment']) & (predictions == predsmaxdiff))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116\n",
      "727 389\n"
     ]
    }
   ],
   "source": [
    "#these are the indexes where both models predicted wrongly\n",
    "bothwrong = np.intersect1d(inxsavgwrong, inxsmaxprobwrong)\n",
    "print len(bothwrong)\n",
    "a = 0\n",
    "b = 0\n",
    "for inx in bothwrong:\n",
    "    score = test1['sentiment'].iloc[inx]\n",
    "    if score == 0 and predictions[inx] == 1:\n",
    "        a = a + 1\n",
    "    elif score == 1 and predictions[inx] == 0:\n",
    "        b = b + 1\n",
    "        \n",
    "print a,b\n",
    "#so most misclassified as positive when really negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547\n"
     ]
    }
   ],
   "source": [
    "#Where averaging was wrong and MaxProb was right\n",
    "print len(np.where((predictions != test1['sentiment']) & (predictions != predsmaxdiff))[0])\n",
    "avgwrong = np.where((predictions != test1['sentiment']) & (predictions != predsmaxdiff))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "783\n"
     ]
    }
   ],
   "source": [
    "#where MaxProb was wrong and averaging right\n",
    "print len(np.where((predsmaxdiff != test1['sentiment']) & (predsmaxdiff != predictions))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get number of sentences for each review on histogram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0         1  doc      diff\n",
      "4   9.995809e-01  0.000419    0  0.999162\n",
      "5   4.492255e-03  0.995508    1  0.991015\n",
      "15  9.869987e-01  0.013001    2  0.973997\n",
      "18  5.788350e-03  0.994212    3  0.988423\n",
      "19  1.381632e-03  0.998618    4  0.997237\n",
      "35  3.088288e-07  1.000000    5  0.999999\n",
      "57  9.987605e-01  0.001240    6  0.997521\n",
      "61  3.031958e-05  0.999970    7  0.999939\n",
      "76  2.828780e-04  0.999717    8  0.999434\n",
      "80  9.923345e-01  0.007665    9  0.984669\n"
     ]
    }
   ],
   "source": [
    "print probsmaxdiff[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
