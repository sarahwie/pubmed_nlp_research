{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from nltk.corpus import stopwords\n",
    "import nltk.data\n",
    "import logging\n",
    "import numpy as np  # Make sure that numpy is imported\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/sarahwie/Documents/DeepLearningMovies_datasets/')\n",
    "from KaggleWord2VecUtility import KaggleWord2VecUtility\n",
    "DATADIR='/home/sarahwie/Documents/DeepLearningMovies_datasets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download()\n",
    "# Load the punkt tokenizer\n",
    "#tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This function replaces all the Kaggle word parsing/cleaning by importing KaggleWord2VecUtility package :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to use this function instead of parsing by sentence:\n",
    "Note* can choose to remove stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getCleanReviews(reviews):\n",
    "    clean_reviews = []\n",
    "    for review in reviews[\"review\"]:\n",
    "        clean_reviews.append( KaggleWord2VecUtility.review_to_wordlist( review, remove_stopwords=False ))\n",
    "    return clean_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data from files\n",
    "train = pd.read_csv( os.path.join(DATADIR, 'labeledTrainData.tsv'), header=0, delimiter=\"\\t\", quoting=3 )\n",
    "unlabeled_train = pd.read_csv( os.path.join(DATADIR, \"unlabeledTrainData.tsv\"), header=0,  delimiter=\"\\t\", quoting=3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read 25000 labeled train reviews and 50000 unlabeled reviews\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Verify the number of reviews that were read (100,000 in total)\n",
    "print \"Read %d labeled train reviews \" \\\n",
    "     \"and %d unlabeled reviews\\n\" % (train[\"review\"].size, unlabeled_train[\"review\"].size )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                                                    \"5814_8\"\n",
       "sentiment                                                    1\n",
       "review       \"With all this stuff going down at the moment ...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.ix[0,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Don't know where this came from. Gets an even split train/test set from our labelled training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OH because Kaggle's test set has no labels so we need our own labelled test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fracTrain = 0.5\n",
    "nSamples = train.shape[0]\n",
    "order = np.random.permutation(nSamples) # come up with a random ordering\n",
    "splitIndex = int(np.round(nSamples*fracTrain))\n",
    "train1 = train.ix[order[:splitIndex],:]\n",
    "test1 = train.ix[order[splitIndex:],:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500, 3)\n",
      "(12500, 3)\n"
     ]
    }
   ],
   "source": [
    "print train1.shape\n",
    "print test1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2Vec inversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is some stuff to split the labelled training set into positive and negative reviews. NOTE: takes a long time to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gets a list of positive review indexes and negative review indexes. Takes those respective reviews and parses them into words and appends to a list of positive and negative words, respectively. Also does the same for the unlabelled training reviews and their words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing words from training set\n",
      "Parsing words from unlabeled set\n"
     ]
    }
   ],
   "source": [
    "# ****** Split the labeled and unlabeled training sets into clean words\n",
    "#\n",
    "inxs_pos = np.where(train1[\"sentiment\"] == 1)[0].tolist()\n",
    "inxs_neg = np.where(train1[\"sentiment\"] == 0)[0].tolist()\n",
    "\n",
    "print \"Parsing words from training set\"\n",
    "reviews_pos = train1.iloc[inxs_pos]\n",
    "words_pos = getCleanReviews(reviews_pos)\n",
    "\n",
    "reviews_neg = train1.iloc[inxs_neg]\n",
    "words_neg = getCleanReviews(reviews_neg)   \n",
    "    \n",
    "print \"Parsing words from unlabeled set\"\n",
    "words_unlabelled = getCleanReviews(unlabeled_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now do the same for all sentences without splitting to build a vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing words from training set\n",
      "Parsing words from unlabeled set\n"
     ]
    }
   ],
   "source": [
    "# ****** Split the labeled and unlabeled training sets into clean words, don't separate by class\n",
    "#\n",
    "words = [] #initialize an empty list\n",
    "\n",
    "print \"Parsing words from training set\"\n",
    "words += getCleanReviews(train1)\n",
    "\n",
    "print \"Parsing words from unlabeled set\"\n",
    "words += getCleanReviews(unlabeled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print words[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print words_neg[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print words_pos[0:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some stuff from Taddy's code (much simpler than Kaggle method). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word2Vec(vocab=0, size=100, alpha=0.025)\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "\n",
    "## create a w2v learner \n",
    "basemodel = Word2Vec(\n",
    "    workers=multiprocessing.cpu_count(), # use your cores\n",
    "    iter=3, # iter = sweeps of SGD through the data; more is better\n",
    "    hs=1, negative=0 # we only have scoring for the hierarchical softmax setup\n",
    "    )\n",
    "print basemodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "basemodel.build_vocab(words) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train 2 models off of the base model (one pos & one neg). This changes now that we have words only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3222425"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "models = [deepcopy(basemodel) for i in range(2)]\n",
    "models[0].train(words_pos, total_examples=len(words_pos) )\n",
    "models[1].train(words_neg, total_examples=len(words_neg) )"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "### Inversion of the distributed representations\n",
    "\n",
    "At this point, we have 5 different word2vec language representations. Each 'model' has been trained conditional (i.e., limited to) text from a specific star rating. We will apply Bayes rule to go from p(text|stars) to p(stars|text).\n",
    "For any new word we can obtain its likelihood (lhd; actually, the composite likelihood approximation; see the paper) using the score function in the word2vec class. We get the likelihood for each word in the first test review, then convert to a probability over star ratings. Every word in the review is evaluated separately and the final star rating of the review is an average vote of all the words. This is all in the following handy wrapper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "docprob takes two lists\n",
    "* docs: a list of documents, each of which is a list of words\n",
    "* models: the candidate word2vec models (each potential class)\n",
    "\n",
    "it returns the array of class probabilities.  Everything is done in-memory.\n",
    "\n",
    "***HERE is where I need to modify how the class probabilities are calculated. Must average across words now instead of sentences.\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd # for quick summing within doc\n",
    "\n",
    "def docprobwords(docs,mods):\n",
    "    sentlist = [s for d in docs for s in d]\n",
    "    llhd = np.array( [ m.score(sentlist, len(sentlist)) for m in mods ] )\n",
    "    lhd = np.exp(llhd - llhd.max(axis=0))\n",
    "    prob = pd.DataFrame( (lhd/lhd.sum(axis=0)).transpose() )\n",
    "    prob[\"doc\"] = [i for i,d in enumerate(docs) for s in d]\n",
    "    prob = prob.groupby(\"doc\").mean()\n",
    "    return prob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test set example\n",
    "As an example, we apply the inversion on the full test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# read in the test set as a list of lists of words\n",
    "docs = getCleanReviews(test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[u'i', u'only', u'lasted', u'mins', u'before', u'self', u'preservation', u'jerked', u'me', u'out', u'of', u'the', u'empty', u'eyed', u'drooling', u'stupor', u'that', u'this', u'film', u'effortlessly', u'induced', u'and', u'propelled', u'me', u'screaming', u'back', u'to', u'the', u'video', u'shop', u'armed', u'for', u'bear', u'to', u'say', u'the', u'film', u'was', u'bad', u'would', u'be', u'a', u'missed', u'opportunity', u'to', u'use', u'words', u'interspersed', u'with', u'characters', u'from', u'the', u'top', u'keys', u'on', u'my', u'keyboard', u'just', u'to', u'keep', u'these', u'comments', u'clean', u'one', u'to', u'be', u'avoided'], [u'the', u'michael', u'keaton', u'kiddie', u'comedy', u'of', u'the', u'same', u'title', u'was', u'roundly', u'condemned', u'for', u'it', u's', u'um', u'shoddy', u'special', u'effects', u'but', u'compared', u'to', u'what', u'screaming', u'mad', u'george', u'cooked', u'up', u'for', u'this', u'horror', u'comedy', u'they', u're', u'positively', u'mind', u'boggling', u'the', u'killer', u'snowman', u'seems', u'to', u'be', u'made', u'out', u'of', u'styrofoam', u'and', u'his', u'arms', u'look', u'like', u'oversized', u'oven', u'mitts', u'which', u'they', u'probably', u'were', u'the', u'cast', u'lays', u'it', u'on', u'thick', u'in', u'this', u'parody', u'of', u'dozens', u'of', u'other', u'much', u'worse', u'movies', u'and', u'paul', u'keith', u'as', u'the', u'town', u'doctor', u'is', u'particularly', u'memorable', u'in', u'a', u'small', u'but', u'hilarious', u'role']]\n"
     ]
    }
   ],
   "source": [
    "print docs[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the probs (note we give docprob our test set plus the models)\n",
    "probswords = docprobwords(docs[0:2], models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doc</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.661443</td>\n",
       "      <td>0.338557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.673901</td>\n",
       "      <td>0.326099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1\n",
       "doc                    \n",
       "0    0.661443  0.338557\n",
       "1    0.673901  0.326099"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the probs (note we give docprob our test set plus the models)\n",
    "probswords = docprobwords(docs, models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A numpy array of ones for the number of docs that we're predicting:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predswords = np.ones((probswords.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500,)\n"
     ]
    }
   ],
   "source": [
    "print np.shape(predswords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predswords[np.where(probswords.iloc[:,1] > 0.5)] = 0 # The second column is actually the negative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  1.,  1., ...,  1.,  1.,  1.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500,)\n",
      "(12500,)\n"
     ]
    }
   ],
   "source": [
    "print predswords.shape\n",
    "print test1[\"sentiment\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4892\n"
     ]
    }
   ],
   "source": [
    "print np.size(np.where(predswords == test1[\"sentiment\"]))*1./np.size(predswords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
