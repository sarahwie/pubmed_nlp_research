{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: a continuation from Histograms_sentences_scores_feature_selection.ipynb\n",
    "\n",
    "We calculate feature importance off of the test set's features because only the test set's sentences get scored (probssentences). Is this legal?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import datetime\n",
    "import numpy as np\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "probssentences = pickle.load(open('/home/sarahwie/Documents/pubmed-nlp-research/pickled_objects/probssentences.p', 'rb'))\n",
    "test1 = pickle.load(open('/home/sarahwie/Documents/pubmed-nlp-research/pickled_objects/test1.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = pickle.load(open('/home/sarahwie/Documents/pubmed-nlp-research/pickled_objects/features.p', 'rb'))\n",
    "labels = pickle.load(open('/home/sarahwie/Documents/pubmed-nlp-research/pickled_objects/labels.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32.25557907   5.14741849   4.07540472   3.25938003   3.49981633\n",
      "   3.7477608    3.70348957   4.12769366   5.27599952  34.9074578 ]\n"
     ]
    }
   ],
   "source": [
    "#get feature weights for each sentence score from 0 to 1 in bins of 10\n",
    "clf = ExtraTreesClassifier()\n",
    "clf = clf.fit(features, labels)\n",
    "weights = clf.feature_importances_  \n",
    "#Normalize so all are greater than 1\n",
    "weights = weights * 100\n",
    "print weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#is the issue that the ET classifier used is fit on the test data? I only want the weights, not the model itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:00:44\n"
     ]
    }
   ],
   "source": [
    "#Apply to the actual sentence scores\n",
    "a = datetime.datetime.now().replace(microsecond=0)\n",
    "\n",
    "probssentences['0_weighted'] = 9.99\n",
    "probssentences['1_weighted'] = 9.99\n",
    "\n",
    "for i in range(len(probssentences)):\n",
    "    valneg = probssentences.iloc[i][0]\n",
    "    inxneg = 99999\n",
    "    if 0 <= valneg < 0.1:\n",
    "        inxneg = 0\n",
    "    elif 0.1 <= valneg < 0.2:\n",
    "        inxneg = 1\n",
    "    elif 0.2 <= valneg < 0.3:\n",
    "        inxneg = 2\n",
    "    elif 0.3 <= valneg < 0.4:\n",
    "        inxneg = 3\n",
    "    elif 0.4 <= valneg < 0.5:\n",
    "        inxneg = 4\n",
    "    elif 0.5 <= valneg < 0.6:\n",
    "        inxneg = 5\n",
    "    elif 0.6 <= valneg < 0.7:\n",
    "        inxneg = 6\n",
    "    elif 0.7 <= valneg < 0.8:\n",
    "        inxneg = 7\n",
    "    elif 0.8 <= valneg < 0.9:\n",
    "        inxneg = 8\n",
    "    elif 0.9 <= valneg <= 1.0:\n",
    "        inxneg = 9\n",
    "    probssentences.set_value(i, '0_weighted', valneg * weights[inxneg])\n",
    "    \n",
    "    valpos = probssentences.iloc[i][1]\n",
    "    inxpos = 9.9\n",
    "    if 0 <= valpos < 0.1:\n",
    "        inxpos = 0\n",
    "    elif 0.1 <= valpos < 0.2:\n",
    "        inxpos = 1\n",
    "    elif 0.2 <= valpos < 0.3:\n",
    "        inxpos = 2\n",
    "    elif 0.3 <= valpos < 0.4:\n",
    "        inxpos = 3\n",
    "    elif 0.4 <= valpos < 0.5:\n",
    "        inxpos = 4\n",
    "    elif 0.5 <= valpos < 0.6:\n",
    "        inxpos = 5\n",
    "    elif 0.6 <= valpos < 0.7:\n",
    "        inxpos = 6\n",
    "    elif 0.7 <= valpos < 0.8:\n",
    "        inxpos = 7\n",
    "    elif 0.8 <= valpos < 0.9:\n",
    "        inxpos = 8\n",
    "    elif 0.9 <= valpos <= 1.0:\n",
    "        inxpos = 9\n",
    "    probssentences.set_value(i, '1_weighted', valpos * weights[inxpos])\n",
    "    \n",
    "b = datetime.datetime.now().replace(microsecond=0)\n",
    "print b-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             0            1 doc  0_weighted  1_weighted\n",
      "0       0.5986       0.4014   0    2.243410    1.404826\n",
      "1   0.00792023      0.99208   0    0.255472   34.630984\n",
      "2     0.369248     0.630752   0    1.203518    2.335985\n",
      "3     0.445318     0.554682   0    1.558533    2.078814\n",
      "4     0.999581  0.000419095   0   34.892829    0.013518\n",
      "5   0.00449226     0.995508   1    0.144900   34.750644\n",
      "6     0.918007    0.0819928   1   32.045295    2.644727\n",
      "7      0.55223      0.44777   1    2.069627    1.567112\n",
      "8     0.986808    0.0131918   1   34.446967    0.425509\n",
      "9     0.721142     0.278858   1    2.976654    1.136459\n",
      "10    0.111639     0.888361   1    0.574651    4.686995\n",
      "11    0.717194     0.282805   1    2.960359    1.152547\n",
      "12   0.0193013     0.980699   2    0.622574   34.233697\n",
      "13   0.0159692     0.984031   2    0.515094   34.350015\n",
      "14   0.0224181     0.977582   2    0.723108   34.124900\n",
      "15    0.986999    0.0130013   2   34.453617    0.419364\n",
      "16   0.0593864     0.940614   3    1.915544   32.834428\n",
      "17   0.0795348     0.920465   3    2.565441   32.131099\n",
      "18  0.00578835     0.994212   3    0.186707   34.705400\n",
      "19  0.00138163     0.998618   4    0.044565   34.859228\n"
     ]
    }
   ],
   "source": [
    "print probssentences[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0_weighted  1_weighted\n",
      "doc                        \n",
      "0      8.030752    8.092825\n",
      "1     10.745493    6.623427\n",
      "2      9.078598   25.781994\n",
      "3      1.555897   33.223643\n",
      "4      9.947820    7.642471\n",
      "5      1.431370   10.375656\n",
      "6     13.528790   12.809105\n",
      "7      0.207365   34.683045\n",
      "8     10.848690    6.896297\n",
      "9     34.639876    0.247252\n"
     ]
    }
   ],
   "source": [
    "prob = probssentences.groupby(\"doc\").mean()\n",
    "print prob[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500,)\n"
     ]
    }
   ],
   "source": [
    "preds = np.ones((prob.shape[0]))\n",
    "print preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds[np.where(prob.iloc[:,0] >  prob.iloc[:,1])] = 0 # The first column is the negative model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12500,)\n",
      "(12500,)\n"
     ]
    }
   ],
   "source": [
    "print preds.shape\n",
    "print test1[\"sentiment\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86848\n"
     ]
    }
   ],
   "source": [
    "print np.size(np.where(preds == test1[\"sentiment\"]))*1./np.size(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.868160030313\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print roc_auc_score(test1[\"sentiment\"], preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Especially considering the weights are fit from the test data itself, we would expect to see a big increase in performance, which we're not getting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? :/ could have something to do with the fact that we fit a classifier on the test data which is pretty wacky. Or could be the way the weights were applied to the sentence scores (unlikely). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This performance is SO similar to word2vec, check if these are the same indices or not.\n",
    "Nope! 463 different of 12500."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "w2vpreds = pickle.load(open('/home/sarahwie/Documents/pubmed-nlp-research/pickled_objects/predictions.p', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.866634984213\n"
     ]
    }
   ],
   "source": [
    "print roc_auc_score(test1[\"sentiment\"], w2vpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print type(preds)\n",
    "print type(w2vpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array_equal(preds, w2vpreds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463\n"
     ]
    }
   ],
   "source": [
    "print len(np.where(preds!=w2vpreds)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "222\n"
     ]
    }
   ],
   "source": [
    "#print indices where w2v was wrong and new method was right\n",
    "print len(np.where((w2vpreds != test1['sentiment']) & (preds != w2vpreds))[0])\n",
    "print len(np.where((preds != test1['sentiment']) & (preds != w2vpreds))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   60,   131,   156,   243,   246,   250,   280,   366,   380,\n",
       "         478,   485,   533,   565,   614,   647,   667,   755,   820,\n",
       "         867,   879,   991,  1010,  1023,  1078,  1079,  1170,  1221,\n",
       "        1294,  1296,  1323,  1348,  1461,  1471,  1645,  1706,  1759,\n",
       "        1804,  1913,  1922,  2050,  2063,  2090,  2140,  2162,  2297,\n",
       "        2305,  2335,  2480,  2631,  2634,  2660,  2682,  2710,  2743,\n",
       "        2748,  2773,  2894,  2936,  2973,  2989,  3016,  3021,  3022,\n",
       "        3038,  3039,  3060,  3102,  3154,  3178,  3210,  3262,  3286,\n",
       "        3325,  3332,  3350,  3365,  3533,  3657,  3861,  3864,  3879,\n",
       "        3914,  3956,  4056,  4113,  4242,  4250,  4412,  4552,  4563,\n",
       "        4627,  4682,  4748,  4773,  4800,  4801,  4870,  4920,  4986,\n",
       "        5005,  5012,  5204,  5222,  5249,  5269,  5272,  5321,  5450,\n",
       "        5471,  5636,  5648,  5790,  5877,  5935,  5937,  5950,  5995,\n",
       "        6014,  6015,  6074,  6240,  6308,  6467,  6486,  6502,  6524,\n",
       "        6578,  6611,  6615,  6645,  6673,  6695,  6704,  6734,  6768,\n",
       "        6804,  6810,  6845,  6992,  7063,  7122,  7236,  7349,  7411,\n",
       "        7450,  7474,  7480,  7580,  7617,  7717,  7741,  7804,  7824,\n",
       "        7869,  7892,  7937,  7973,  8026,  8112,  8158,  8176,  8186,\n",
       "        8188,  8273,  8445,  8496,  8503,  8563,  8672,  8712,  8762,\n",
       "        8792,  8948,  9011,  9032,  9168,  9200,  9219,  9266,  9410,\n",
       "        9411,  9414,  9435,  9436,  9439,  9535,  9564,  9618,  9697,\n",
       "        9718,  9766,  9776,  9809,  9847,  9867,  9876,  9886,  9895,\n",
       "        9907,  9914,  9949,  9950,  9958,  9976, 10040, 10098, 10133,\n",
       "       10134, 10187, 10249, 10291, 10568, 10630, 10641, 10693, 10947,\n",
       "       10981, 11025, 11139, 11183, 11198, 11238, 11349, 11434, 11476,\n",
       "       11547, 11553, 11569, 11625, 11655, 11665, 11744, 11834, 11837,\n",
       "       11856, 12020, 12110, 12244, 12351, 12433, 12439])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where((w2vpreds != test1['sentiment']) & (preds != w2vpreds))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               0            1 doc  0_weighted  1_weighted\n",
      "695     0.986983    0.0130174  60   34.453053    0.419882\n",
      "696    0.0317208     0.968279  60    1.023172   33.800167\n",
      "697     0.653628     0.346372  60    2.420704    1.128958\n",
      "698     0.997484   0.00251651  60   34.819615    0.081172\n",
      "699    0.0193894     0.980611  60    0.625418   34.230623\n",
      "700     0.999291  0.000708568  60   34.882723    0.022855\n",
      "701     0.126453     0.873547  60    0.650905    4.608835\n",
      "702     0.579535     0.420465  60    2.171959    1.471550\n",
      "703  0.000281299     0.999719  60    0.009073   34.897639\n"
     ]
    }
   ],
   "source": [
    "print probssentences.loc[probssentences['doc']==60]\n",
    "#.groupby('doc').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.DataFrameGroupBy object at 0x7f2c644d3c10>\n"
     ]
    }
   ],
   "source": [
    "print probssentences.loc[probssentences['doc']==60].groupby('doc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
